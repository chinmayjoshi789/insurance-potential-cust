{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ID NAME DESCRIPTION 1 MOSTYPE Customer Subtype\n",
    "2 MAANTHUI Number of houses\n",
    "3 MGEMOMV Avg size household\n",
    "4 MGEMLEEF Avg age\n",
    "5 MOSHOOFD Customer main type\n",
    "6 MGODRK Roman catholic\n",
    "7 MGODPR Protestant ...\n",
    "8 MGODOV Other religion\n",
    "9 MGODGE No religion\n",
    "10 MRELGE Married\n",
    "11 MRELSA Living together\n",
    "12 MRELOV Other relation\n",
    "13 MFALLEEN Singles\n",
    "14 MFGEKIND Household without children\n",
    "15 MFWEKIND Household with children\n",
    "16 MOPLHOOG High level education\n",
    "17 MOPLMIDD Medium level education\n",
    "18 MOPLLAAG Lower level education\n",
    "19 MBERHOOG High status\n",
    "20 MBERZELF Entrepreneur\n",
    "21 MBERBOER Farmer\n",
    "22 MBERMIDD Middle management\n",
    "23 MBERARBG Skilled labourers\n",
    "24 MBERARBO Unskilled labourers\n",
    "25 MSKA Social class A\n",
    "26 MSKB1 Social class B1\n",
    "27 MSKB2 Social class B2\n",
    "28 MSKC Social class C\n",
    "29 MSKD Social class D\n",
    "30 MHHUUR Rented house\n",
    "31 MHKOOP Home owners\n",
    "32 MAUT1 1 car\n",
    "33 MAUT2 2 cars\n",
    "34 MAUT0 No car\n",
    "35 MZFONDS National Health Service\n",
    "36 MZPART Private health insurance\n",
    "37 MINKM30 Income < 30\n",
    "38 MINK3045 Income 30-45.000\n",
    "39 MINK4575 Income 45-75.000\n",
    "40 MINK7512 Income 75-122.000\n",
    "41 MINK123M Income >123.000\n",
    "42 MINKGEM Average income\n",
    "43 MKOOPKLA Purchasing power class\n",
    "44 PWAPART Contribution private third party insurance see 45 PWABEDR Contribution third party insurance (firms) ... 46 PWALAND Contribution third party insurane (agriculture)\n",
    "47 PPERSAUT Contribution car policies\n",
    "48 PBESAUT Contribution delivery van policies\n",
    "49 PMOTSCO Contribution motorcycle/scooter policies\n",
    "50 PVRAAUT Contribution lorry policies\n",
    "51 PAANHANG Contribution trailer policies\n",
    "52 PTRACTOR Contribution tractor policies\n",
    "53 PWERKT Contribution agricultural machines policies\n",
    "54 PBROM Contribution moped policies\n",
    "55 PLEVEN Contribution life insurances\n",
    "56 PPERSONG Contribution private accident insurance policies\n",
    "57 PGEZONG Contribution family accidents insurance policies\n",
    "58 PWAOREG Contribution disability insurance policies\n",
    "59 PBRAND Contribution fire policies\n",
    "60 PZEILPL Contribution surfboard policies\n",
    "61 PPLEZIER Contribution boat policies\n",
    "62 PFIETS Contribution bicycle policies\n",
    "63 PINBOED Contribution property insurance policies\n",
    "64 PBYSTAND Contribution social security insurance policies\n",
    "65 AWAPART Number of private third party insurance 66 AWABEDR Number of third party insurance (firms) ... 67 AWALAND Number of third party insurane (agriculture) 68 APERSAUT Number of car policies\n",
    "69 ABESAUT Number of delivery van policies\n",
    "70 AMOTSCO Number of motorcycle/scooter policies\n",
    "71 AVRAAUT Number of lorry policies\n",
    "72 AAANHANG Number of trailer policies\n",
    "73 ATRACTOR Number of tractor policies\n",
    "74 AWERKT Number of agricultural machines policies\n",
    "75 ABROM Number of moped policies\n",
    "76 ALEVEN Number of life insurances\n",
    "77 APERSONG Number of private accident insurance policies 78 AGEZONG Number of family accidents insurance policies 79 AWAOREG Number of disability insurance policies\n",
    "80 ABRAND Number of fire policies\n",
    "81 AZEILPL Number of surfboard policies\n",
    "82 APLEZIER Number of boat policies\n",
    "83 AFIETS Number of bicycle policies\n",
    "84 AINBOED Number of property insurance policies\n",
    "85 ABYSTAND Number of social security insurance policies 86 CARAVAN Number of mobile home policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier,RandomForestRegressor,BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score,roc_auc_score,classification_report,mean_squared_error,accuracy_score,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('D:\\datasets+minipro\\EDV Projects\\carvan_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['MOSTYPE', 'MAANTHI', 'MGEMOMV', 'MGEMLEEF', 'MOSHOOFD',\n",
    "       'MGODRK', 'MGODPR', 'MGODOV', 'MGODGE', 'MRELGE', 'MRELSA',\n",
    "       'MRELOV', 'MFALLEEN', 'MFGEKIND', 'MFWEKIND', 'MOPLHOOG',\n",
    "       'MOPLMIDD', 'MOPLLAAG', 'MBERHOOG', 'MBERZELF', 'MBERBOER',\n",
    "       'MBERMIDD', 'MBERARBG', 'MBERARBO', 'MSKA', 'MSKB1', 'MSKB2',\n",
    "       'MSKC', 'MSKD', 'MHHR', 'MHKOOP', 'MAT1', 'MAT2', 'MAT0',\n",
    "       'MZFONDS', 'MZPART', 'MINKM30', 'MINK3045', 'MINK4575',\n",
    "       'MINK7512', 'MINK123M', 'MINKGEM', 'MKOOPKLA', 'PWAPART',\n",
    "       'PWABEDR', 'PWALAND', 'PPERSAT', 'PBESAT', 'PMOTSCO', 'PVRAAT',\n",
    "       'PAANHANG', 'PTRACTOR', 'PWERKT', 'PBROM', 'PLEVEN', 'PPERSONG',\n",
    "       'PGEZONG', 'PWAOREG', 'PBRAND', 'PZEILPL', 'PPLEZIER', 'PFIETS',\n",
    "       'PINBOED', 'PBYSTAND', 'AWAPART', 'AWABEDR', 'AWALAND',\n",
    "       'APERSAT', 'ABESAT', 'AMOTSCO', 'AVRAAT', 'AAANHANG',\n",
    "       'ATRACTOR', 'AWERKT', 'ABROM', 'ALEVEN', 'APERSONG', 'AGEZONG',\n",
    "       'AWAOREG', 'ABRAND', 'AZEILPL', 'APLEZIER', 'AFIETS', 'AINBOED',\n",
    "       'ABYSTAND', 'CARAVAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOSTYPE</th>\n",
       "      <th>MAANTHI</th>\n",
       "      <th>MGEMOMV</th>\n",
       "      <th>MGEMLEEF</th>\n",
       "      <th>MOSHOOFD</th>\n",
       "      <th>MGODRK</th>\n",
       "      <th>MGODPR</th>\n",
       "      <th>MGODOV</th>\n",
       "      <th>MGODGE</th>\n",
       "      <th>MRELGE</th>\n",
       "      <th>MRELSA</th>\n",
       "      <th>MRELOV</th>\n",
       "      <th>MFALLEEN</th>\n",
       "      <th>MFGEKIND</th>\n",
       "      <th>MFWEKIND</th>\n",
       "      <th>MOPLHOOG</th>\n",
       "      <th>MOPLMIDD</th>\n",
       "      <th>MOPLLAAG</th>\n",
       "      <th>MBERHOOG</th>\n",
       "      <th>MBERZELF</th>\n",
       "      <th>MBERBOER</th>\n",
       "      <th>MBERMIDD</th>\n",
       "      <th>MBERARBG</th>\n",
       "      <th>MBERARBO</th>\n",
       "      <th>MSKA</th>\n",
       "      <th>MSKB1</th>\n",
       "      <th>MSKB2</th>\n",
       "      <th>MSKC</th>\n",
       "      <th>MSKD</th>\n",
       "      <th>MHHR</th>\n",
       "      <th>MHKOOP</th>\n",
       "      <th>MAT1</th>\n",
       "      <th>MAT2</th>\n",
       "      <th>MAT0</th>\n",
       "      <th>MZFONDS</th>\n",
       "      <th>MZPART</th>\n",
       "      <th>MINKM30</th>\n",
       "      <th>MINK3045</th>\n",
       "      <th>MINK4575</th>\n",
       "      <th>MINK7512</th>\n",
       "      <th>MINK123M</th>\n",
       "      <th>MINKGEM</th>\n",
       "      <th>MKOOPKLA</th>\n",
       "      <th>PWAPART</th>\n",
       "      <th>PWABEDR</th>\n",
       "      <th>PWALAND</th>\n",
       "      <th>PPERSAT</th>\n",
       "      <th>PBESAT</th>\n",
       "      <th>PMOTSCO</th>\n",
       "      <th>PVRAAT</th>\n",
       "      <th>PAANHANG</th>\n",
       "      <th>PTRACTOR</th>\n",
       "      <th>PWERKT</th>\n",
       "      <th>PBROM</th>\n",
       "      <th>PLEVEN</th>\n",
       "      <th>PPERSONG</th>\n",
       "      <th>PGEZONG</th>\n",
       "      <th>PWAOREG</th>\n",
       "      <th>PBRAND</th>\n",
       "      <th>PZEILPL</th>\n",
       "      <th>PPLEZIER</th>\n",
       "      <th>PFIETS</th>\n",
       "      <th>PINBOED</th>\n",
       "      <th>PBYSTAND</th>\n",
       "      <th>AWAPART</th>\n",
       "      <th>AWABEDR</th>\n",
       "      <th>AWALAND</th>\n",
       "      <th>APERSAT</th>\n",
       "      <th>ABESAT</th>\n",
       "      <th>AMOTSCO</th>\n",
       "      <th>AVRAAT</th>\n",
       "      <th>AAANHANG</th>\n",
       "      <th>ATRACTOR</th>\n",
       "      <th>AWERKT</th>\n",
       "      <th>ABROM</th>\n",
       "      <th>ALEVEN</th>\n",
       "      <th>APERSONG</th>\n",
       "      <th>AGEZONG</th>\n",
       "      <th>AWAOREG</th>\n",
       "      <th>ABRAND</th>\n",
       "      <th>AZEILPL</th>\n",
       "      <th>APLEZIER</th>\n",
       "      <th>AFIETS</th>\n",
       "      <th>AINBOED</th>\n",
       "      <th>ABYSTAND</th>\n",
       "      <th>CARAVAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.00000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "      <td>5822.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>24.253349</td>\n",
       "      <td>1.110615</td>\n",
       "      <td>2.678805</td>\n",
       "      <td>2.991240</td>\n",
       "      <td>5.773617</td>\n",
       "      <td>0.696496</td>\n",
       "      <td>4.626932</td>\n",
       "      <td>1.069907</td>\n",
       "      <td>3.258502</td>\n",
       "      <td>6.183442</td>\n",
       "      <td>0.883545</td>\n",
       "      <td>2.290450</td>\n",
       "      <td>1.887667</td>\n",
       "      <td>3.230333</td>\n",
       "      <td>4.300240</td>\n",
       "      <td>1.461010</td>\n",
       "      <td>3.351254</td>\n",
       "      <td>4.572484</td>\n",
       "      <td>1.895053</td>\n",
       "      <td>0.397973</td>\n",
       "      <td>0.522329</td>\n",
       "      <td>2.899004</td>\n",
       "      <td>2.219856</td>\n",
       "      <td>2.306424</td>\n",
       "      <td>1.620749</td>\n",
       "      <td>1.606836</td>\n",
       "      <td>2.202508</td>\n",
       "      <td>3.758674</td>\n",
       "      <td>1.067331</td>\n",
       "      <td>4.236860</td>\n",
       "      <td>4.771728</td>\n",
       "      <td>6.040364</td>\n",
       "      <td>1.316386</td>\n",
       "      <td>1.959464</td>\n",
       "      <td>6.277053</td>\n",
       "      <td>2.728959</td>\n",
       "      <td>2.573686</td>\n",
       "      <td>3.536070</td>\n",
       "      <td>2.731364</td>\n",
       "      <td>0.796118</td>\n",
       "      <td>0.202679</td>\n",
       "      <td>3.784438</td>\n",
       "      <td>4.236345</td>\n",
       "      <td>0.771213</td>\n",
       "      <td>0.040021</td>\n",
       "      <td>0.071625</td>\n",
       "      <td>2.970457</td>\n",
       "      <td>0.048265</td>\n",
       "      <td>0.175369</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.020955</td>\n",
       "      <td>0.092580</td>\n",
       "      <td>0.013054</td>\n",
       "      <td>0.215046</td>\n",
       "      <td>0.194778</td>\n",
       "      <td>0.013741</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>0.023531</td>\n",
       "      <td>1.827722</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.018894</td>\n",
       "      <td>0.025249</td>\n",
       "      <td>0.01563</td>\n",
       "      <td>0.047578</td>\n",
       "      <td>0.402954</td>\n",
       "      <td>0.014772</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.562178</td>\n",
       "      <td>0.010477</td>\n",
       "      <td>0.041051</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.033665</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.076606</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.570079</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.006012</td>\n",
       "      <td>0.031776</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.014256</td>\n",
       "      <td>0.059773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.846706</td>\n",
       "      <td>0.405842</td>\n",
       "      <td>0.789835</td>\n",
       "      <td>0.814589</td>\n",
       "      <td>2.856760</td>\n",
       "      <td>1.003234</td>\n",
       "      <td>1.715843</td>\n",
       "      <td>1.017503</td>\n",
       "      <td>1.597647</td>\n",
       "      <td>1.909482</td>\n",
       "      <td>0.965924</td>\n",
       "      <td>1.722645</td>\n",
       "      <td>1.799928</td>\n",
       "      <td>1.619973</td>\n",
       "      <td>2.005283</td>\n",
       "      <td>1.622967</td>\n",
       "      <td>1.761052</td>\n",
       "      <td>2.298125</td>\n",
       "      <td>1.798321</td>\n",
       "      <td>0.775073</td>\n",
       "      <td>1.056926</td>\n",
       "      <td>1.839675</td>\n",
       "      <td>1.730840</td>\n",
       "      <td>1.692843</td>\n",
       "      <td>1.722882</td>\n",
       "      <td>1.330664</td>\n",
       "      <td>1.529319</td>\n",
       "      <td>1.935568</td>\n",
       "      <td>1.303175</td>\n",
       "      <td>3.089302</td>\n",
       "      <td>3.089837</td>\n",
       "      <td>1.552799</td>\n",
       "      <td>1.203072</td>\n",
       "      <td>1.599714</td>\n",
       "      <td>1.978675</td>\n",
       "      <td>1.981893</td>\n",
       "      <td>2.086099</td>\n",
       "      <td>1.882656</td>\n",
       "      <td>1.927738</td>\n",
       "      <td>1.162829</td>\n",
       "      <td>0.551557</td>\n",
       "      <td>1.317783</td>\n",
       "      <td>2.007150</td>\n",
       "      <td>0.958623</td>\n",
       "      <td>0.362680</td>\n",
       "      <td>0.499980</td>\n",
       "      <td>2.920669</td>\n",
       "      <td>0.531346</td>\n",
       "      <td>0.897222</td>\n",
       "      <td>0.244675</td>\n",
       "      <td>0.212738</td>\n",
       "      <td>0.603076</td>\n",
       "      <td>0.228906</td>\n",
       "      <td>0.813133</td>\n",
       "      <td>0.898100</td>\n",
       "      <td>0.209260</td>\n",
       "      <td>0.192471</td>\n",
       "      <td>0.375274</td>\n",
       "      <td>1.879290</td>\n",
       "      <td>0.043462</td>\n",
       "      <td>0.273028</td>\n",
       "      <td>0.156894</td>\n",
       "      <td>0.20456</td>\n",
       "      <td>0.409016</td>\n",
       "      <td>0.492631</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.142092</td>\n",
       "      <td>0.604767</td>\n",
       "      <td>0.129991</td>\n",
       "      <td>0.228974</td>\n",
       "      <td>0.062819</td>\n",
       "      <td>0.125775</td>\n",
       "      <td>0.240755</td>\n",
       "      <td>0.124189</td>\n",
       "      <td>0.265112</td>\n",
       "      <td>0.377569</td>\n",
       "      <td>0.072782</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.077403</td>\n",
       "      <td>0.562058</td>\n",
       "      <td>0.022696</td>\n",
       "      <td>0.081632</td>\n",
       "      <td>0.210986</td>\n",
       "      <td>0.090463</td>\n",
       "      <td>0.119996</td>\n",
       "      <td>0.237087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MOSTYPE      MAANTHI      MGEMOMV     MGEMLEEF     MOSHOOFD  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean     24.253349     1.110615     2.678805     2.991240     5.773617   \n",
       "std      12.846706     0.405842     0.789835     0.814589     2.856760   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%      10.000000     1.000000     2.000000     2.000000     3.000000   \n",
       "50%      30.000000     1.000000     3.000000     3.000000     7.000000   \n",
       "75%      35.000000     1.000000     3.000000     3.000000     8.000000   \n",
       "max      41.000000    10.000000     5.000000     6.000000    10.000000   \n",
       "\n",
       "            MGODRK       MGODPR       MGODOV       MGODGE       MRELGE  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.696496     4.626932     1.069907     3.258502     6.183442   \n",
       "std       1.003234     1.715843     1.017503     1.597647     1.909482   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     4.000000     0.000000     2.000000     5.000000   \n",
       "50%       0.000000     5.000000     1.000000     3.000000     6.000000   \n",
       "75%       1.000000     6.000000     2.000000     4.000000     7.000000   \n",
       "max       9.000000     9.000000     5.000000     9.000000     9.000000   \n",
       "\n",
       "            MRELSA       MRELOV     MFALLEEN     MFGEKIND     MFWEKIND  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.883545     2.290450     1.887667     3.230333     4.300240   \n",
       "std       0.965924     1.722645     1.799928     1.619973     2.005283   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     0.000000     2.000000     3.000000   \n",
       "50%       1.000000     2.000000     2.000000     3.000000     4.000000   \n",
       "75%       1.000000     3.000000     3.000000     4.000000     6.000000   \n",
       "max       7.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "          MOPLHOOG     MOPLMIDD     MOPLLAAG     MBERHOOG     MBERZELF  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      1.461010     3.351254     4.572484     1.895053     0.397973   \n",
       "std       1.622967     1.761052     2.298125     1.798321     0.775073   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     2.000000     3.000000     0.000000     0.000000   \n",
       "50%       1.000000     3.000000     5.000000     2.000000     0.000000   \n",
       "75%       2.000000     4.000000     6.000000     3.000000     1.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     5.000000   \n",
       "\n",
       "          MBERBOER     MBERMIDD     MBERARBG     MBERARBO         MSKA  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.522329     2.899004     2.219856     2.306424     1.620749   \n",
       "std       1.056926     1.839675     1.730840     1.692843     1.722882   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     2.000000     1.000000     1.000000     0.000000   \n",
       "50%       0.000000     3.000000     2.000000     2.000000     1.000000   \n",
       "75%       1.000000     4.000000     3.000000     3.000000     2.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "             MSKB1        MSKB2         MSKC         MSKD         MHHR  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      1.606836     2.202508     3.758674     1.067331     4.236860   \n",
       "std       1.330664     1.529319     1.935568     1.303175     3.089302   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     2.000000     0.000000     2.000000   \n",
       "50%       2.000000     2.000000     4.000000     1.000000     4.000000   \n",
       "75%       2.000000     3.000000     5.000000     2.000000     7.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "            MHKOOP         MAT1         MAT2         MAT0      MZFONDS  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      4.771728     6.040364     1.316386     1.959464     6.277053   \n",
       "std       3.089837     1.552799     1.203072     1.599714     1.978675   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     5.000000     0.000000     1.000000     5.000000   \n",
       "50%       5.000000     6.000000     1.000000     2.000000     7.000000   \n",
       "75%       7.000000     7.000000     2.000000     3.000000     8.000000   \n",
       "max       9.000000     9.000000     7.000000     9.000000     9.000000   \n",
       "\n",
       "            MZPART      MINKM30     MINK3045     MINK4575     MINK7512  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      2.728959     2.573686     3.536070     2.731364     0.796118   \n",
       "std       1.981893     2.086099     1.882656     1.927738     1.162829   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     2.000000     1.000000     0.000000   \n",
       "50%       2.000000     2.000000     4.000000     3.000000     0.000000   \n",
       "75%       4.000000     4.000000     5.000000     4.000000     1.000000   \n",
       "max       9.000000     9.000000     9.000000     9.000000     9.000000   \n",
       "\n",
       "          MINK123M      MINKGEM     MKOOPKLA      PWAPART      PWABEDR  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.202679     3.784438     4.236345     0.771213     0.040021   \n",
       "std       0.551557     1.317783     2.007150     0.958623     0.362680   \n",
       "min       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "25%       0.000000     3.000000     3.000000     0.000000     0.000000   \n",
       "50%       0.000000     4.000000     4.000000     0.000000     0.000000   \n",
       "75%       0.000000     4.000000     6.000000     2.000000     0.000000   \n",
       "max       9.000000     9.000000     8.000000     3.000000     6.000000   \n",
       "\n",
       "           PWALAND      PPERSAT       PBESAT      PMOTSCO       PVRAAT  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.071625     2.970457     0.048265     0.175369     0.009447   \n",
       "std       0.499980     2.920669     0.531346     0.897222     0.244675   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     5.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     6.000000     0.000000     0.000000     0.000000   \n",
       "max       4.000000     8.000000     7.000000     7.000000     9.000000   \n",
       "\n",
       "          PAANHANG     PTRACTOR       PWERKT        PBROM       PLEVEN  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.020955     0.092580     0.013054     0.215046     0.194778   \n",
       "std       0.212738     0.603076     0.228906     0.813133     0.898100   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       5.000000     6.000000     6.000000     6.000000     9.000000   \n",
       "\n",
       "          PPERSONG      PGEZONG      PWAOREG       PBRAND      PZEILPL  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.013741     0.015287     0.023531     1.827722     0.000859   \n",
       "std       0.209260     0.192471     0.375274     1.879290     0.043462   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     2.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     4.000000     0.000000   \n",
       "max       6.000000     3.000000     7.000000     8.000000     3.000000   \n",
       "\n",
       "          PPLEZIER       PFIETS     PINBOED     PBYSTAND      AWAPART  \\\n",
       "count  5822.000000  5822.000000  5822.00000  5822.000000  5822.000000   \n",
       "mean      0.018894     0.025249     0.01563     0.047578     0.402954   \n",
       "std       0.273028     0.156894     0.20456     0.409016     0.492631   \n",
       "min       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.00000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.00000     0.000000     1.000000   \n",
       "max       6.000000     1.000000     6.00000     5.000000     2.000000   \n",
       "\n",
       "           AWABEDR      AWALAND      APERSAT       ABESAT      AMOTSCO  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.014772     0.020611     0.562178     0.010477     0.041051   \n",
       "std       0.134133     0.142092     0.604767     0.129991     0.228974   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     1.000000     0.000000     0.000000   \n",
       "max       5.000000     1.000000     7.000000     4.000000     8.000000   \n",
       "\n",
       "            AVRAAT     AAANHANG     ATRACTOR       AWERKT        ABROM  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.002233     0.012539     0.033665     0.006183     0.070423   \n",
       "std       0.062819     0.125775     0.240755     0.124189     0.265112   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       3.000000     3.000000     4.000000     6.000000     2.000000   \n",
       "\n",
       "            ALEVEN     APERSONG      AGEZONG      AWAOREG       ABRAND  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.076606     0.005325     0.006527     0.004638     0.570079   \n",
       "std       0.377569     0.072782     0.080532     0.077403     0.562058   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "max       8.000000     1.000000     1.000000     2.000000     7.000000   \n",
       "\n",
       "           AZEILPL     APLEZIER       AFIETS      AINBOED     ABYSTAND  \\\n",
       "count  5822.000000  5822.000000  5822.000000  5822.000000  5822.000000   \n",
       "mean      0.000515     0.006012     0.031776     0.007901     0.014256   \n",
       "std       0.022696     0.081632     0.210986     0.090463     0.119996   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     2.000000     3.000000     2.000000     2.000000   \n",
       "\n",
       "           CARAVAN  \n",
       "count  5822.000000  \n",
       "mean      0.059773  \n",
       "std       0.237087  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if df[i].isnull().sum()>0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=' '.join(map(str,(df.columns.tolist()))).lower()\n",
    "col=a.split(' ')\n",
    "df.columns=col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting X & y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('caravan',1)\n",
    "y=df['caravan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier,RandomForestRegressor,BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score,roc_auc_score,classification_report,mean_squared_error,accuracy_score,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.775445</td>\n",
       "      <td>0.940368</td>\n",
       "      <td>0.940469</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ada boost</td>\n",
       "      <td>0.750902</td>\n",
       "      <td>0.940613</td>\n",
       "      <td>0.936463</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.038095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.669509</td>\n",
       "      <td>0.989448</td>\n",
       "      <td>0.924442</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.629296</td>\n",
       "      <td>0.981595</td>\n",
       "      <td>0.925587</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decistion Tree</td>\n",
       "      <td>0.544861</td>\n",
       "      <td>0.993620</td>\n",
       "      <td>0.886090</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.152381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 names  auc_score  training   testing  precision    recall\n",
       "0  Logistic Regression   0.775445  0.940368  0.940469   0.666667  0.019048\n",
       "1            Ada boost   0.750902  0.940613  0.936463   0.285714  0.038095\n",
       "2        Random Forest   0.669509  0.989448  0.924442   0.064516  0.019048\n",
       "3              Bagging   0.629296  0.981595  0.925587   0.162162  0.057143\n",
       "4       Decistion Tree   0.544861  0.993620  0.886090   0.126984  0.152381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed for same results everytime\n",
    "seed=0\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "X=df.drop('caravan',1)\n",
    "y=df['caravan']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =3)\n",
    "\n",
    "#declare the models\n",
    "lr = LogisticRegression()\n",
    "rf=RandomForestClassifier(n_estimators=17,random_state=0)\n",
    "adb=ensemble.AdaBoostClassifier()\n",
    "bgc=ensemble.BaggingClassifier()\n",
    "# gnb = GaussianNB()\n",
    "# knn=KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "# ab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators=2,random_state=0)\n",
    "# ab_dt = AdaBoostClassifier(base_estimator=dt,n_estimators=21,random_state=0)\n",
    "# ab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\n",
    "# ab_lr=  AdaBoostClassifier(base_estimator=lr,n_estimators=29,random_state=0)\n",
    "# bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=17)\n",
    "# xgb = XGBClassifier()\n",
    "\n",
    "models=[lr,rf,adb,bgc,dt]\n",
    "sctr,scte,auc,ps,rs=[],[],[],[],[]\n",
    "def ens(X_train,X_test, y_train, y_test):\n",
    "    for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            y_test_pred_new=model.predict_proba(X_test)\n",
    "            y_test_pred_new=y_test_pred_new[:,1]\n",
    "            train_score=model.score(X_train,y_train)\n",
    "            test_score=model.score(X_test,y_test)\n",
    "            p_score=metrics.precision_score(y_test,y_test_pred)\n",
    "            r_score=metrics.recall_score(y_test,y_test_pred)\n",
    "            \n",
    "            ac=metrics.roc_auc_score(y_test,y_test_pred_new)\n",
    "            \n",
    "            sctr.append(train_score)\n",
    "            scte.append(test_score)\n",
    "            ps.append(p_score)\n",
    "            rs.append(r_score)\n",
    "            auc.append(ac)\n",
    "    return sctr,scte,auc,ps,rs\n",
    "ens(X_train,X_test, y_train, y_test)\n",
    "\n",
    "ensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n",
    "                                'Decistion Tree'],\n",
    "                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\n",
    "ensemble=ensemble.sort_values(by=['auc_score','precision','recall'],ascending=False).reset_index(drop=True)\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5474\n",
       "1     348\n",
       "Name: caravan, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['caravan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note that precision,recall is sharply reduced due to imbalanced data.\n",
    "## So,lets try with applying smote technique and see if any improvment is there in precision and recall!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try with oversampling technique SMOTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here,We will try to increase minority samples to level of majority..This is called SMOTE(synthetic minority oversampling)technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote_X=df.drop('caravan',axis=1)\n",
    "smote_Y=df['caravan']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =3)\n",
    "\n",
    "# smote_X = telcom[cols]\n",
    "# smote_Y = telcom[target_col]\n",
    "\n",
    "#Split train and test data\n",
    "smote_train_X,smote_test_X,smote_train_Y,smote_test_Y = train_test_split(smote_X,smote_Y,\n",
    "                                                                         test_size = .25 ,\n",
    "                                                                         random_state = 1)\n",
    "\n",
    "#oversampling minority class using smote\n",
    "os = SMOTE(random_state = 0)\n",
    "os_smote_X,os_smote_Y = os.fit_sample(smote_train_X,smote_train_Y)\n",
    "os_smote_X = pd.DataFrame(data = os_smote_X,columns=smote_X.columns)\n",
    "os_smote_Y = pd.DataFrame(data = os_smote_Y,columns=['caravan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.986789</td>\n",
       "      <td>0.996516</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.949194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.982221</td>\n",
       "      <td>0.993033</td>\n",
       "      <td>0.949614</td>\n",
       "      <td>0.959638</td>\n",
       "      <td>0.939516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ada boost</td>\n",
       "      <td>0.956247</td>\n",
       "      <td>0.891134</td>\n",
       "      <td>0.887444</td>\n",
       "      <td>0.878836</td>\n",
       "      <td>0.900806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.927216</td>\n",
       "      <td>0.852813</td>\n",
       "      <td>0.846810</td>\n",
       "      <td>0.856907</td>\n",
       "      <td>0.835484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decistion Tree</td>\n",
       "      <td>0.906241</td>\n",
       "      <td>0.997213</td>\n",
       "      <td>0.904510</td>\n",
       "      <td>0.899761</td>\n",
       "      <td>0.912097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 names  auc_score  training   testing  precision    recall\n",
       "0        Random Forest   0.986789  0.996516  0.956522   0.963964  0.949194\n",
       "1              Bagging   0.982221  0.993033  0.949614   0.959638  0.939516\n",
       "2            Ada boost   0.956247  0.891134  0.887444   0.878836  0.900806\n",
       "3  Logistic Regression   0.927216  0.852813  0.846810   0.856907  0.835484\n",
       "4       Decistion Tree   0.906241  0.997213  0.904510   0.899761  0.912097"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed for same results everytime\n",
    "seed=0\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "X=os_smote_X\n",
    "y=os_smote_Y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state =3)\n",
    "\n",
    "#declare the models\n",
    "lr = LogisticRegression()\n",
    "rf=RandomForestClassifier(n_estimators=17,random_state=0)\n",
    "adb=ensemble.AdaBoostClassifier()\n",
    "bgc=ensemble.BaggingClassifier()\n",
    "# gnb = GaussianNB()\n",
    "# knn=KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "# ab_rf = AdaBoostClassifier(base_estimator=rf,n_estimators=2,random_state=0)\n",
    "# ab_dt = AdaBoostClassifier(base_estimator=dt,n_estimators=21,random_state=0)\n",
    "# ab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\n",
    "# ab_lr=  AdaBoostClassifier(base_estimator=lr,n_estimators=29,random_state=0)\n",
    "# bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0, n_estimators=17)\n",
    "# xgb = XGBClassifier()\n",
    "\n",
    "models=[lr,rf,adb,bgc,dt]\n",
    "sctr,scte,auc,ps,rs=[],[],[],[],[]\n",
    "def ens(X_train,X_test, y_train, y_test):\n",
    "    for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            y_test_pred_new=model.predict_proba(X_test)\n",
    "            y_test_pred_new=y_test_pred_new[:,1]\n",
    "            train_score=model.score(X_train,y_train)\n",
    "            test_score=model.score(X_test,y_test)\n",
    "            p_score=metrics.precision_score(y_test,y_test_pred)\n",
    "            r_score=metrics.recall_score(y_test,y_test_pred)\n",
    "            ac=metrics.roc_auc_score(y_test,y_test_pred_new)            \n",
    "            sctr.append(train_score)\n",
    "            scte.append(test_score)\n",
    "            ps.append(p_score)\n",
    "            rs.append(r_score)\n",
    "            auc.append(ac)\n",
    "    return sctr,scte,auc,ps,rs\n",
    "ens(X_train,X_test, y_train, y_test)\n",
    "\n",
    "ensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n",
    "                                'Decistion Tree'],\n",
    "                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\n",
    "ensemble=ensemble.sort_values(by=['auc_score','precision','recall'],ascending=False).reset_index(drop=True)\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=os_smote_X\n",
    "y=os_smote_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing with cross validation using K Fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_avg = []\n",
    "auc_var = []\n",
    "for ne in np.arange(1,30):\n",
    "    RF=RandomForestClassifier(n_estimators=ne,random_state=0)\n",
    "    kfold = KFold(shuffle=True,n_splits=5,random_state=0)\n",
    "    auc = cross_val_score(RF, X, y, cv=kfold, scoring='roc_auc')\n",
    "    auc_avg.append(1 - np.mean(auc))\n",
    "    auc_var.append(np.var(auc,ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Error: 0.012235919515263816  n_estimator: 29 Min Variance Error: 5.580283819975646e-06\n"
     ]
    }
   ],
   "source": [
    "print('Bias Error:',auc_avg[np.argmin(auc_var)],' n_estimator:',np.argmin(auc_var)+1,'Min Variance Error:',np.min(auc_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=29,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF=RandomForestClassifier(n_estimators=29)\n",
    "RF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Train: \n",
      " [[3245   10]\n",
      " [   7 3299]]\n",
      "Overall Accuracy 0.9974089315653102\n",
      "Confusion Matrix - Test: \n",
      " [[807  39]\n",
      " [ 43 752]]\n",
      "Overall Accuracy 0.9500304692260817\n",
      "log loss:  1.7259054531885771\n",
      "auc-roc score:  0.9889505925033825\n",
      "precision score:  0.9506953223767383\n",
      "recall score:  0.9459119496855346\n",
      "F1 score:  0.9482976040353089\n"
     ]
    }
   ],
   "source": [
    "y_prob_train = RF.predict_proba(X_train)\n",
    "y_pred_train = RF.predict(X_train)\n",
    "y_prob_test = RF.predict_proba(X_test)\n",
    "y_prob_test=y_prob_test[:,1]\n",
    "y_pred_test = RF.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\n",
    "print('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n",
    "print('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n",
    "      \n",
    "from sklearn.metrics import log_loss\n",
    "print('log loss: ',log_loss(y_test,y_pred_test))\n",
    "print('auc-roc score: ',metrics.roc_auc_score(y_test,y_prob_test))\n",
    "print('precision score: ',metrics.precision_score(y_test,y_pred_test))\n",
    "print('recall score: ',metrics.recall_score(y_test,y_pred_test))\n",
    "print('F1 score: ',metrics.f1_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=os_smote_X\n",
    "y=os_smote_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 9, 'min_samples_leaf': 11}\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt_params = {'max_depth':np.arange(1,10), 'min_samples_leaf':np.arange(2,15), 'criterion':['entropy','gini']}\n",
    "gscv = GridSearchCV(dt, dt_params, cv=5, scoring='roc_auc')\n",
    "gscv.fit(X, y)\n",
    "print(gscv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8868568641794684"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_best_DT=gscv.best_params_\n",
    "DT=DecisionTreeClassifier(**gscv_best_DT)\n",
    "DT.fit(X,y)\n",
    "DT.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix - Train: \n",
      " [[2746  509]\n",
      " [ 234 3072]]\n",
      "Overall Accuracy 0.8867550678250267\n",
      "Confusion Matrix - Test: \n",
      " [[716 130]\n",
      " [ 55 740]]\n",
      "Overall Accuracy 0.8872638634978671\n",
      "log loss:  3.8938315543719697\n",
      "auc-roc score:  0.9457424505999374\n",
      "precision score:  0.8505747126436781\n",
      "recall score:  0.9308176100628931\n",
      "F1 score:  0.888888888888889\n"
     ]
    }
   ],
   "source": [
    "y_prob_train = DT.predict_proba(X_train)\n",
    "y_pred_train = DT.predict(X_train)\n",
    "y_prob_test = DT.predict_proba(X_test)\n",
    "y_prob_test=y_prob_test[:,1]\n",
    "y_pred_test = DT.predict(X_test)\n",
    "\n",
    "print('Confusion Matrix - Train:', '\\n', confusion_matrix(y_train, y_pred_train))\n",
    "print('Overall Accuracy', accuracy_score(y_train, y_pred_train))\n",
    "print('Confusion Matrix - Test:', '\\n', confusion_matrix(y_test, y_pred_test))\n",
    "print('Overall Accuracy', accuracy_score(y_test, y_pred_test))\n",
    "      \n",
    "from sklearn.metrics import log_loss\n",
    "print('log loss: ',log_loss(y_test,y_pred_test))\n",
    "print('auc-roc score: ',metrics.roc_auc_score(y_test,y_prob_test))\n",
    "print('precision score: ',metrics.precision_score(y_test,y_pred_test))\n",
    "print('recall score: ',metrics.recall_score(y_test,y_pred_test))\n",
    "print('F1 score: ',metrics.f1_score(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import plot_tree,export_text\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plot_tree(DT)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "disp=plot_roc_curve(lr,X_test,y_test)\n",
    "plot_roc_curve(RF,X_test,y_test,ax=disp.ax_)\n",
    "plot_roc_curve(DT,X_test,y_test,ax=disp.ax_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfte=pd.read_csv('D:\\datasets+minipro\\EDV Projects\\carvan_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['MOSTYPE', 'MAANTHI', 'MGEMOMV', 'MGEMLEEF', 'MOSHOOFD',\n",
    "       'MGODRK', 'MGODPR', 'MGODOV', 'MGODGE', 'MRELGE', 'MRELSA',\n",
    "       'MRELOV', 'MFALLEEN', 'MFGEKIND', 'MFWEKIND', 'MOPLHOOG',\n",
    "       'MOPLMIDD', 'MOPLLAAG', 'MBERHOOG', 'MBERZELF', 'MBERBOER',\n",
    "       'MBERMIDD', 'MBERARBG', 'MBERARBO', 'MSKA', 'MSKB1', 'MSKB2',\n",
    "       'MSKC', 'MSKD', 'MHHR', 'MHKOOP', 'MAT1', 'MAT2', 'MAT0',\n",
    "       'MZFONDS', 'MZPART', 'MINKM30', 'MINK3045', 'MINK4575',\n",
    "       'MINK7512', 'MINK123M', 'MINKGEM', 'MKOOPKLA', 'PWAPART',\n",
    "       'PWABEDR', 'PWALAND', 'PPERSAT', 'PBESAT', 'PMOTSCO', 'PVRAAT',\n",
    "       'PAANHANG', 'PTRACTOR', 'PWERKT', 'PBROM', 'PLEVEN', 'PPERSONG',\n",
    "       'PGEZONG', 'PWAOREG', 'PBRAND', 'PZEILPL', 'PPLEZIER', 'PFIETS',\n",
    "       'PINBOED', 'PBYSTAND', 'AWAPART', 'AWABEDR', 'AWALAND',\n",
    "       'APERSAT', 'ABESAT', 'AMOTSCO', 'AVRAAT', 'AAANHANG',\n",
    "       'ATRACTOR', 'AWERKT', 'ABROM', 'ALEVEN', 'APERSONG', 'AGEZONG',\n",
    "       'AWAOREG', 'ABRAND', 'AZEILPL', 'APLEZIER', 'AFIETS', 'AINBOED',\n",
    "       'ABYSTAND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=' '.join(map(str,(df.columns.tolist()))).lower()\n",
    "col=a.split(' ')\n",
    "dfte.columns=col[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=os_smote_X\n",
    "y=os_smote_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=29,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF=RandomForestClassifier(n_estimators=29)\n",
    "RF.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf=pd.DataFrame(RF.predict(dfte),columns=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3842\n",
       "1     158\n",
       "Name: predictions, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rf['predictions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf.to_csv('D:\\datasets+minipro\\EDV Projects\\caravansub.csv',columns=['predictions'],index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dfte.columns:\n",
    "    if dfte[i].isnull().sum()>0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
